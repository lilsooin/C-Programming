### char type

char
```C
char ch_a = 'a'; 
char ch_b = ch_a + 1; /* b */
char ch_c = 99;       /* c */
```
- At least 8bit integer type
- Standard is greater than 8bit
- So complier can define char size is 1million size

### ASCII Code
- 'A' = 65
- 'a' = 65 + 32 = 95

### finding char size
- **<limits.h>** header file includes,
		see  **CHAR_BIT**. you can find bit size
- c standard doesn't force exact data size
  - each compile has different data size
- 1 Byte is **CHAR_BIT** 
  - 1 Byte can be 8bit
  - 1 Byte can be 16bit
- Small device needs small data size


### char and ASCII Code
char
```C
char ch_a = 'a'; 
char ch_b = ch_a + 1; /* b */
char ch_c = 99;       /* c */
```
- Integer type
- char is enough to define ASCII code
- ASCII is `0-126`(7bit)(extended ASCII is greater)
  
### char and signed/unsigned
- 
   

- In C#, an unsigned data type is prefixed with the letter '**u**'
	- data type 'byte' is unsigned data type
	- To use signed byte, prefixed with the letter 's'
	 
- In C, should use '**unsigned**' word in front of the data type
	- eg. `unsigned char`, `unsigned int`
	- Can use `signed` word in front of the data type
		- eg. `signed char`, `signed int`
	- If it doesn't use `unsigned/signed`, we can assume it is **signed**
	- `signed int`  usually skip the **signed**

### unsigned and signed example

C#
```C#
byte unsignedByte = 300;
sbyte signedByte = -1000;

int signedInt = - 10000;
uint usignedInt = 5000;
```



C
```C
char default_char = 100;
signed char signed_char = -100;
unsigned char unsigned_char = 500;

int default_int = -1000;
signed int signed_int = -100;
unsigned int unsigned_int = 500;
```